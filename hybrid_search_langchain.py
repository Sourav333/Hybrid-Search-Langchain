# -*- coding: utf-8 -*-
"""Hybrid Search Langchain.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SwXmurxcY3iZ-VCUcC_F4Ahh6nIVUpFr
"""

!pip install --upgrade --quiet pinecone-client pinecone-text pinecone-notebooks

api_key="80db1ef6-d771-4ab1-8af1-27e0fcfcee94"

!pip install langchain-community

from langchain_community.retrievers import PineconeHybridSearchRetriever

import os
from pinecone import Pinecone,ServerlessSpec
index_name="hybrid-search-langchain-pinecone"

## initialize the pinecone client
pc=Pinecone(api_key=api_key,environment="us-west1-gcp")

## create a index
if index_name not in pc.list_indexes().names():
    pc.create_index(
        name=index_name,
        dimension=384, #dimension of the dense vector
        metric="dotproduct", ##sparse values supported only for dotproduct
        spec=ServerlessSpec(cloud='aws',region="us-east-1"),
    )

index=pc.Index(index_name)
index

!pip install langchain-huggingface

!pip install python-dotenv

## vectore embedding and sparse matrix
import os
from dotenv import load_dotenv
load_dotenv()

# os.environ["HF_TOKEN"]=os.getenv("HF_TOKEN")

from langchain_huggingface import HuggingFaceEmbeddings
embeddings=HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2",
    # Ã·model_kwargs={"device":"cpu"}
    model_kwargs={
        "use_auth_token": "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"  # Directly pass the environment token
    }
)
embeddings

from pinecone_text.sparse import BM25Encoder

bm25_encoder=BM25Encoder().default()
bm25_encoder

!pip install nltk

import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# Download NLTK resources
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')

# Initialize stopwords and lemmatizer
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
    # 1. Normalize the text: lowercase and remove special characters
    text = text.lower()
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Remove special characters and punctuation
    text = text.strip()  # Remove extra spaces

    # 2. Remove stopwords
    tokens = text.split()  # Tokenize the text
    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords

    # 3. Lemmatize each token
    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatize each word

    # Join tokens back to form the cleaned sentence
    preprocessed_text = ' '.join(tokens)

    return preprocessed_text

# Example of text preprocessing
sentences = [
    "In 2023, I visited Paris!",
    "In 2022, I visited London.",
    "In 2021, I visited Tokyo."
]

# Apply preprocessing to all sentences
preprocessed_sentences = [preprocess_text(sentence) for sentence in sentences]

print(preprocessed_sentences)

# sentences=[
#     "In 2023,I visited Paris",
#     "In 2022,I visited London",
#     "In 2021,I visited Tokyo",
# ]

##tfidf values on these sentences
bm25_encoder.fit(preprocessed_sentences)


## store the value on json file
bm25_encoder.dump("bm25_values.json")

!pip install langchain

from langchain.retrievers import PineconeHybridSearchRetriever  # Import the class

retriever=PineconeHybridSearchRetriever(embeddings=embeddings,
                                        sparse_encoder=bm25_encoder,
                                        index=index,
                                        alpha=0.6  # This might represent the dense_weight, review documentation for clarity
                                        )
retriever

retriever.add_texts(
    [
        "In 2023,I visited Paris",
        "In 2022,I visited London",
        "In 2021,I visited Tokyo",
    ]
)

retriever.invoke("Which year did I visit Paris?")

retriever.invoke("which city I visited in 2021?")

retriever.add_texts(preprocessed_sentences)

retriever.invoke("Which year did I visit Paris?")

retriever.invoke("which city I visited in 2021?")